{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    " <h3>Initial OLS Regression for Exploratory Data Analysis </h3>\n",
    "<center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               Withdraw   R-squared:                       0.990\n",
      "Model:                            OLS   Adj. R-squared:                  0.990\n",
      "Method:                 Least Squares   F-statistic:                 3.656e+05\n",
      "Date:                Fri, 08 Nov 2024   Prob (F-statistic):               0.00\n",
      "Time:                        20:58:38   Log-Likelihood:                -51380.\n",
      "No. Observations:               22000   AIC:                         1.028e+05\n",
      "Df Residuals:                   21993   BIC:                         1.028e+05\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     10.4284      0.111     94.198      0.000      10.211      10.645\n",
      "Shops          0.1081      0.001    110.062      0.000       0.106       0.110\n",
      "ATMs          -1.0096      0.009   -106.982      0.000      -1.028      -0.991\n",
      "Downtown     -36.1897      0.887    -40.781      0.000     -37.929     -34.450\n",
      "Workday       -3.5011      0.037    -93.806      0.000      -3.574      -3.428\n",
      "Center         7.1931      0.056    129.352      0.000       7.084       7.302\n",
      "High           0.9566      0.037     26.035      0.000       0.885       1.029\n",
      "==============================================================================\n",
      "Omnibus:                    17745.344   Durbin-Watson:                   1.998\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           468940.833\n",
      "Skew:                           3.781   Prob(JB):                         0.00\n",
      "Kurtosis:                      24.316   Cond. No.                     4.45e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.45e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('ATM_sample.csv')\n",
    "\n",
    "# Fit the OLS regression model using a formula\n",
    "ols_model = smf.ols(formula='Withdraw ~ Shops + ATMs + Downtown + Workday + Center + High', data=data).fit()\n",
    "\n",
    "# Print the summary of the OLS regression\n",
    "print(ols_model.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h3> Ridge Regression model implementation </h3>\n",
    "<center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Test Ridge configuration to see which model will be the best option <center>\n",
    "<center>Finding output: 'Model': 'Polynomial Degree 3 + Interactions' <center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance Summary:\n",
      "{'Model': 'Base Features', 'Poly Degree': 1, 'Interactions': False, 'Best Alpha': 0.009102981779915217, 'MSE (CV)': 6.277284680511846, 'Validation MSE': 6.202448279230941}\n",
      "{'Model': 'With Interactions', 'Poly Degree': 1, 'Interactions': True, 'Best Alpha': 0.009102981779915217, 'MSE (CV)': 6.277284680511798, 'Validation MSE': 6.202448279231076}\n",
      "{'Model': 'Polynomial Degree 2', 'Poly Degree': 2, 'Interactions': False, 'Best Alpha': 0.040949150623804234, 'MSE (CV)': 6.22156500390486, 'Validation MSE': 6.127093280965384}\n",
      "{'Model': 'Polynomial Degree 2 + Interactions', 'Poly Degree': 2, 'Interactions': True, 'Best Alpha': 0.05963623316594643, 'MSE (CV)': 1.5560108496512348, 'Validation MSE': 1.6408938452361017}\n",
      "{'Model': 'Polynomial Degree 3', 'Poly Degree': 3, 'Interactions': False, 'Best Alpha': 0.0029470517025518097, 'MSE (CV)': 6.221782268707377, 'Validation MSE': 6.127521167198706}\n",
      "{'Model': 'Polynomial Degree 3 + Interactions', 'Poly Degree': 3, 'Interactions': True, 'Best Alpha': 0.019306977288832496, 'MSE (CV)': 0.24795233408230963, 'Validation MSE': 0.2510014460178545}\n",
      "\n",
      "Best Model Configuration: {'Model': 'Polynomial Degree 3 + Interactions', 'Poly Degree': 3, 'Interactions': True, 'Best Alpha': 0.019306977288832496, 'MSE (CV)': 0.24795233408230963, 'Validation MSE': 0.2510014460178545}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load Data\n",
    "data = pd.read_csv('ATM_sample.csv')\n",
    "X = data[['Shops', 'ATMs', 'Downtown', 'Workday', 'Center', 'High']]\n",
    "y = data['Withdraw']\n",
    "\n",
    "# Split Data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define Model Configurations\n",
    "configs = [\n",
    "    {'name': 'Base Features', 'poly_degree': 1, 'interactions': False},\n",
    "    {'name': 'With Interactions', 'poly_degree': 1, 'interactions': True},\n",
    "    {'name': 'Polynomial Degree 2', 'poly_degree': 2, 'interactions': False},\n",
    "    {'name': 'Polynomial Degree 2 + Interactions', 'poly_degree': 2, 'interactions': True},\n",
    "    {'name': 'Polynomial Degree 3', 'poly_degree': 3, 'interactions': False},\n",
    "    {'name': 'Polynomial Degree 3 + Interactions', 'poly_degree': 3, 'interactions': True}\n",
    "]\n",
    "\n",
    "alphas = np.logspace(-4, 4, 50)\n",
    "results = []\n",
    "\n",
    "def add_polynomial_terms(X, degree):\n",
    "    X_poly = X.copy()\n",
    "    if degree >= 2:\n",
    "        X_poly['Shops^2'] = X['Shops'] ** 2\n",
    "        X_poly['ATMs^2'] = X['ATMs'] ** 2\n",
    "    if degree >= 3:\n",
    "        X_poly['Shops^3'] = X['Shops'] ** 3\n",
    "        X_poly['ATMs^3'] = X['ATMs'] ** 3\n",
    "    return X_poly\n",
    "\n",
    "# Iterate over configurations\n",
    "for config in configs:\n",
    "    if config['interactions']:\n",
    "        poly = PolynomialFeatures(degree=config['poly_degree'], include_bias=False)\n",
    "        X_train_poly = poly.fit_transform(X_train)\n",
    "        X_val_poly = poly.transform(X_val)\n",
    "    else:\n",
    "        X_train_poly = add_polynomial_terms(X_train, config['poly_degree'])\n",
    "        X_val_poly = add_polynomial_terms(X_val, config['poly_degree'])\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_poly_scaled = scaler.fit_transform(X_train_poly)\n",
    "    X_val_poly_scaled = scaler.transform(X_val_poly)\n",
    "\n",
    "    ridge = Ridge()\n",
    "    param_grid = {'alpha': alphas}\n",
    "    grid_search = GridSearchCV(ridge, param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "    grid_search.fit(X_train_poly_scaled, y_train)\n",
    "\n",
    "    best_alpha = grid_search.best_params_['alpha']\n",
    "    best_mse_cv = -grid_search.best_score_\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    y_val_pred = best_model.predict(X_val_poly_scaled)\n",
    "    val_mse = mean_squared_error(y_val, y_val_pred)\n",
    "\n",
    "    results.append({\n",
    "        'Model': config['name'],\n",
    "        'Poly Degree': config['poly_degree'],\n",
    "        'Interactions': config['interactions'],\n",
    "        'Best Alpha': best_alpha,\n",
    "        'MSE (CV)': best_mse_cv,\n",
    "        'Validation MSE': val_mse\n",
    "    })\n",
    "\n",
    "# Display Results\n",
    "print(\"\\nModel Performance Summary:\")\n",
    "for result in results:\n",
    "    print(result)\n",
    "\n",
    "# Save best configuration for Part 2\n",
    "best_config = min(results, key=lambda x: x['Validation MSE'])\n",
    "print(\"\\nBest Model Configuration:\", best_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Apply Ridge Regularization on entire dataset <center>\n",
    "<center>Model: Polynomial Degree 3 (for ATMs and Shops) + Interactions<center>\n",
    "<center>Best alpha: 0.019306977288832496<center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Summary:\n",
      "=====================================\n",
      "Best Alpha: 0.019306977288832496\n",
      "R-squared: 0.9996\n",
      "Mean Squared Error (MSE): 0.2474\n",
      "Cross-Validation Test MSE: 0.2487\n",
      "AIC: -30613.3491\n",
      "BIC: -30165.4164\n",
      "=====================================\n",
      "                Feature  Coefficient  Std Error\n",
      "              Intercept    54.652818        NaN\n",
      "                Shops^2     6.787656   3.084617\n",
      "                  Shops     6.592232   1.211432\n",
      "       Shops^2 Downtown     6.447716   2.948906\n",
      "   Shops Workday Center    -4.768004   0.313408\n",
      "         Shops Downtown     4.648742   2.851448\n",
      "                Shops^3     4.445164   1.796655\n",
      "           Shops Center     4.000660   1.097849\n",
      "                   ATMs    -3.702765   0.230480\n",
      "           Shops^2 ATMs    -1.293415   2.053351\n",
      "     Shops ATMs Workday     1.236881   0.989502\n",
      "    Shops Downtown High    -1.222662   2.755235\n",
      "    Shops ATMs Downtown     1.212712   2.931315\n",
      "               Downtown    -1.168996   1.638568\n",
      "                 Center     1.016487   0.125169\n",
      "  ATMs Downtown Workday    -0.995535   0.909528\n",
      "                Workday    -0.881871   0.116670\n",
      "         Shops^2 Center     0.860075   1.577282\n",
      "        Shops^2 Workday    -0.759804   1.607889\n",
      "           Shops^2 High     0.565613   1.580212\n",
      "       Downtown Workday     0.515912   1.610618\n",
      "      Shops ATMs Center    -0.493818   0.789566\n",
      " Shops Downtown Workday     0.489574   2.755307\n",
      "             Shops High     0.428070   1.141088\n",
      "                   High     0.394188   0.125934\n",
      "          ATMs Downtown     0.390484   2.027555\n",
      "  Shops Downtown Center     0.381943   2.752699\n",
      "          Shops Workday    -0.345567   1.276353\n",
      "Downtown Workday Center     0.333025   0.283238\n",
      "             Shops ATMs    -0.317027   2.724996\n",
      "   ATMs Downtown Center     0.309256   0.717179\n",
      "        ATMs^2 Downtown    -0.295188   1.312240\n",
      "          Downtown High     0.270401   1.588898\n",
      "        Shops ATMs High     0.264714   0.838526\n",
      "     ATMs Downtown High    -0.200603   0.765378\n",
      "     Shops Workday High    -0.174004   0.333520\n",
      "           Shops ATMs^2     0.157486   1.411799\n",
      "                 ATMs^2     0.136527   0.294017\n",
      "   Downtown Center High     0.125778   0.188009\n",
      "        Downtown Center    -0.121280   1.573964\n",
      "  Downtown Workday High     0.113563   0.303056\n",
      "         ATMs^2 Workday    -0.108792   0.089198\n",
      "      Shops Center High    -0.105715   0.208224\n",
      "            ATMs^2 High    -0.104564   0.069601\n",
      "          ATMs^2 Center     0.087327   0.064513\n",
      "         Workday Center     0.055900   0.040212\n",
      "      ATMs Workday High     0.054741   0.032883\n",
      "           ATMs Workday    -0.050279   0.119489\n",
      "            ATMs Center     0.042823   0.105577\n",
      "              ATMs High     0.041996   0.109962\n",
      "       ATMs Center High    -0.033286   0.020712\n",
      "                 ATMs^3     0.024745   0.152831\n",
      "            Center High     0.016727   0.027468\n",
      "    ATMs Workday Center    -0.015441   0.031410\n",
      "           Workday High     0.007913   0.041958\n",
      "    Workday Center High     0.000495   0.007872\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score, make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Load Data \n",
    "data = pd.read_csv('ATM_sample.csv')\n",
    "X = data[['Shops', 'ATMs', 'Downtown', 'Workday', 'Center', 'High']]\n",
    "y = data['Withdraw']\n",
    "\n",
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X_poly = poly.fit_transform(X)\n",
    "feature_names = poly.get_feature_names_out(X.columns)\n",
    "\n",
    "# Function to check if a feature is valid (no higher powers or redundant dummy interactions)\n",
    "def is_valid_feature(feature):\n",
    "    terms = feature.split()  \n",
    "    for term in terms:\n",
    "        if '^' in term:\n",
    "            var, exp = term.split('^')\n",
    "            if var in ['Downtown', 'Workday', 'Center', 'High'] and int(exp) > 1:\n",
    "                return False \n",
    "    return True\n",
    "\n",
    "# Filter valid features\n",
    "valid_feature_indices = [i for i, feature in enumerate(feature_names) if is_valid_feature(feature)]\n",
    "filtered_features = [feature_names[i] for i in valid_feature_indices]\n",
    "X_poly_filtered = X_poly[:, valid_feature_indices]\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_poly_scaled = scaler.fit_transform(X_poly_filtered)\n",
    "\n",
    "# Ridge Regression with the best alpha determined from Part 1\n",
    "best_alpha = 0.019306977288832496  \n",
    "ridge_best = Ridge(alpha=best_alpha)\n",
    "ridge_best.fit(X_poly_scaled, y)\n",
    "\n",
    "# Predictions and Metrics\n",
    "y_pred_full = ridge_best.predict(X_poly_scaled)\n",
    "mse_full = mean_squared_error(y, y_pred_full)\n",
    "r2_full = r2_score(y, y_pred_full)\n",
    "\n",
    "# Cross-Validation to Get Test MSE\n",
    "mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "cv_mse_scores = cross_val_score(ridge_best, X_poly_scaled, y, scoring=mse_scorer, cv=5)\n",
    "cv_test_mse = -np.mean(cv_mse_scores) \n",
    "\n",
    "# AIC and BIC Calculations\n",
    "n_full = X.shape[0]\n",
    "k_full = X_poly_scaled.shape[1] + 1  # Number of parameters\n",
    "aic_full = n_full * np.log(mse_full) + 2 * k_full\n",
    "bic_full = n_full * np.log(mse_full) + k_full * np.log(n_full)\n",
    "\n",
    "# Generate Summary\n",
    "residuals = y - y_pred_full\n",
    "residual_var = np.var(residuals, ddof=1)\n",
    "ridge_penalty_matrix = best_alpha * np.eye(X_poly_scaled.shape[1])\n",
    "cov_matrix = np.linalg.inv(X_poly_scaled.T @ X_poly_scaled + ridge_penalty_matrix)\n",
    "standard_errors = np.sqrt(residual_var * cov_matrix.diagonal())\n",
    "\n",
    "summary_df = pd.DataFrame({\n",
    "    \"Feature\": [\"Intercept\"] + filtered_features,\n",
    "    \"Coefficient\": [ridge_best.intercept_] + ridge_best.coef_.tolist(),\n",
    "    \"Std Error\": [np.nan] + standard_errors.tolist()\n",
    "})\n",
    "\n",
    "# Sort by the absolute value of coefficients in descending order\n",
    "summary_df['Abs Coefficient'] = summary_df['Coefficient'].abs()\n",
    "summary_df = summary_df.sort_values(by=\"Abs Coefficient\", ascending=False).drop(columns=\"Abs Coefficient\")\n",
    "\n",
    "# Print Final Model Summary\n",
    "print(\"\\nModel Summary:\")\n",
    "print(\"=====================================\")\n",
    "print(f\"Best Alpha: {best_alpha}\")\n",
    "print(f\"R-squared: {r2_full:.4f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_full:.4f}\")\n",
    "print(f\"Cross-Validation Test MSE: {cv_test_mse:.4f}\")\n",
    "print(f\"AIC: {aic_full:.4f}\")\n",
    "print(f\"BIC: {bic_full:.4f}\")\n",
    "print(\"=====================================\")\n",
    "print(summary_df.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
